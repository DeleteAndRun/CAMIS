---
title: "R Template"
---

# XGBoost
XGBoost which stands for eXtreme Gradient Boosting is an efficent implementation of gradient boosting. Gradient boosting is an ensemble technique in machine learning. Unlike traditional models that learn from the data independently, boosting combines the predictions of multiple weak learners to create a single, more accurate strong learner. 

An XGBoost model is based on trees, so we don’t need to do much preprocessing for our data; we don’t need to worry about the factors or centering or scaling our data. 


## Available R packages

**Optional** If there is only one available package this can be deleted. Otherwise please make a short list, paragraph or table. If there is a reason to use one package vs another please include it. Please make sure to include what version of the packages you are using

## Data used

Data used for this example is `birthwt` which is part of the {MASS} package. This data-set considers a number of risk factors associated with birth weight in infants. 

```{r}
library(MASS)

head(birthwt)
```

## Example Code

### Example using {package name}

**Optional** if there is more than one package
