---
title: "R Template"
---

# XGBoost
XGBoost which stands for eXtreme Gradient Boosting is an efficent implementation of gradient boosting. Gradient boosting is an ensemble technique in machine learning. Unlike traditional models that learn from the data independently, boosting combines the predictions of multiple weak learners to create a single, more accurate strong learner. 

An XGBoost model is based on trees, so we don’t need to do much preprocessing for our data; we don’t need to worry about the factors or centering or scaling our data. 


## Available R packages

There are multiple packages that can be used to to implement xgboost in R.

-   [{tidymodels}](https://www.tidymodels.org/)
-   [{xgboost}](https://cran.r-project.org/web/packages/xgboost/index.html)
-   [{caret}](https://cran.r-project.org/web/packages/caret/index.html)

{tidymodels} and {caret} easy ways to access xgboost easily. This example will use {tidymodels} because of the functionality included in {tidymodels} and is being heavily supported by Posit.

## Data used

Data used for this example is `birthwt` which is part of the {MASS} package. This data-set considers a number of risk factors associated with birth weight in infants. 

```{r}
library(MASS)

head(birthwt)
```

## Example Code

### Example using {package name}

**Optional** if there is more than one package
